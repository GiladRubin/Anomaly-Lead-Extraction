{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "from datetime import date, datetime, timedelta\n",
    "import radar\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idanattias/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/idanattias/Downloads/workshop/requests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#leave only informative columns\n",
    "df_subset = df.filter(items = ['TimeStamp', 'RoleInst', 'Continent', 'OpName', 'Country', 'Host', 'Response', 'ReqDuration'])\n",
    "df_subset = df_subset.replace(np.nan, 'Null', regex=True)\n",
    "\n",
    "#convert columns to proper type\n",
    "df_subset['TimeStamp'] = pd.to_datetime(df_subset['TimeStamp'])\n",
    "categorical_columns = list(set(df_subset.columns.values) - set(['TimeStamp', 'ReqDuration']))\n",
    "for col in categorical_columns:\n",
    "    df_subset[col] = df_subset[col].astype('category')\n",
    "\n",
    "#subset df to contain only full data (continuous data flow stopped on 2015-10-07 at 18:00)\n",
    "df_subset = df_subset[df_subset['TimeStamp'] < pd.to_datetime('2015-10-07 18:00')]\n",
    "df_subset = df_subset.sort_values(by = 'TimeStamp')\n",
    "\n",
    "#print ('\\ninfo:')\n",
    "#print df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#remove outliers: keep only the ones that are within +3 to -3 standard deviations in the column 'ReqDuration'\n",
    "df_subset=df_subset[np.abs(df_subset.ReqDuration-df_subset.ReqDuration.mean())<=(3*df_subset.ReqDuration.std())]\n",
    "\n",
    "#df_subset\n",
    "#df_subset.plot(x='TimeStamp',y='ReqDuration')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#these variables store essential information about the data\n",
    "req_dur_sum=df_subset['ReqDuration'].sum()\n",
    "req_dur_per_day=[0 for i in range(7)]\n",
    "req_dur_per_hour=[[0 for i in range(24)] for i in range(7)]\n",
    "num_of_events_per_hour=[[0 for i in range(24)] for i in range(7)]\n",
    "num_of_events_per_day=[0 for i in range(7)]\n",
    "mean_per_hour=[[0 for i in range(24)] for i in range(7)] #average, not mean!\n",
    "new_mean_per_hour= [[0 for i in range(24)] for i in range(7)]\n",
    "std_per_hour= [[0 for i in range(24)] for i in range(7)]\n",
    "mean_per_day= [0 for i in range(7)]\n",
    "fraction_of_hour_per_day= [[0 for i in range(24)] for i in range(7)]\n",
    "fraction_of_typical_hour= [0 for i in range(24)]\n",
    "\n",
    "list_for_calc_std=[]\n",
    "\n",
    "day=df_subset.iloc[0,0].day\n",
    "hour=df_subset.iloc[0,0].hour\n",
    "\n",
    "#update arrays above\n",
    "for index, event in df_subset.iterrows():\n",
    "    if day < event['TimeStamp'].day:\n",
    "        #update std for each hour\n",
    "        std_per_hour[day-1][hour]=np.std(list_for_calc_std)\n",
    "        day+=1\n",
    "        hour=0\n",
    "        list_for_calc_std=[]\n",
    "    \n",
    "    if hour < event['TimeStamp'].hour:\n",
    "        #update std for each hour\n",
    "        std_per_hour[day-1][hour]=np.std(list_for_calc_std)\n",
    "        hour+=1\n",
    "        list_for_calc_std=[]\n",
    "    \n",
    "    list_for_calc_std.append(event['ReqDuration'])\n",
    "    \n",
    "    req_dur_per_day[day-1]+= event['ReqDuration']\n",
    "    req_dur_per_hour[day-1][hour] += event['ReqDuration']\n",
    "    num_of_events_per_hour[day-1][hour]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## updates of information about the data ##\n",
    "\n",
    "#update mean for each hour\n",
    "for i in range (7):\n",
    "    for j in range(24):\n",
    "        if (num_of_events_per_hour[i][j]==0):\n",
    "            mean_per_hour[i][j]=0\n",
    "        else:\n",
    "            mean_per_hour[i][j]= req_dur_per_hour[i][j]/num_of_events_per_hour[i][j]\n",
    "            \n",
    "#update number of events per day\n",
    "temp=0\n",
    "for i in range (7):\n",
    "    for j in range(24):\n",
    "        temp+= num_of_events_per_hour[i][j]\n",
    "        if(j==23):\n",
    "            num_of_events_per_day[i]=temp\n",
    "            temp=0\n",
    "\n",
    "\n",
    "\n",
    "#update mean per day\n",
    "for i in range(7):\n",
    "    mean_per_day[i] = req_dur_per_day[i]/num_of_events_per_day[i]\n",
    "    \n",
    "\n",
    "#update fraction_of_hour_per_day\n",
    "for i in range (7):\n",
    "    for j in range(24):\n",
    "        fraction_of_hour_per_day[i][j] = mean_per_hour[i][j]/mean_per_day[i]\n",
    "\n",
    "# modify to dataframe\n",
    "headers=[i+1 for i in range(24)]\n",
    "df_fraction_of_hour_per_day= DataFrame(fraction_of_hour_per_day, columns=headers)\n",
    "\n",
    "\n",
    "sum_of_columns=df_fraction_of_hour_per_day.sum(axis=0)\n",
    "sum_of_fraction_of_typical_hour =sum_of_columns.tolist()\n",
    "\n",
    "\n",
    "for i in range (24):\n",
    "    if (j>=18):\n",
    "        fraction_of_typical_hour[i]= sum_of_fraction_of_typical_hour[i]/6\n",
    "    else:\n",
    "        fraction_of_typical_hour[i]= sum_of_fraction_of_typical_hour[i]/7\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(24):\n",
    "        new_mean_per_hour[i][j]= mean_per_day[i]*fraction_of_typical_hour[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## creating the synthetic data starts here. first phase: create clean data ##\n",
    "\n",
    "artificial_df = pd.DataFrame(columns=['TimeStamp','ReqDuration'])\n",
    "std= 70\n",
    "\n",
    "for i in range (7):\n",
    "    for j in range(24):\n",
    "        \n",
    "        #edge case\n",
    "        if(j==23): \n",
    "            start = datetime(year=2015, month=10, day=i+1,hour=j,minute=0,second=0)\n",
    "            stop = datetime(year=2015, month=10, day=i+2,hour=0,minute=0,second=0)\n",
    "       \n",
    "        else:\n",
    "            start = datetime(year=2015, month=10, day=i+1,hour=j,minute=0,second=0)\n",
    "            stop = datetime(year=2015, month=10, day=i+1,hour=j+1,minute=0,second=0)\n",
    "        \n",
    "        temp_timestamps=[]\n",
    "       \n",
    "        #create random time stamps\n",
    "        #4144= num of events per hour on average\n",
    "        for event in xrange(4144): \n",
    "            temp_timestamps.append(radar.random_datetime(start=start, stop=stop))\n",
    "        \n",
    "        #create points with normal distribution for each hour\n",
    "       \n",
    "        #if(i==6 and j>=17):   #edge case: this hour has no data\n",
    "        #    std=1                    \n",
    "        #else: \n",
    "        #   std=std_per_hour[i][j]\n",
    "       \n",
    "\n",
    "        temp_points= list(np.random.normal(new_mean_per_hour[i][j],std,4144))\n",
    "        \n",
    "        #create list of tuples: (timestamp,value)\n",
    "        zipped=zip(temp_timestamps,temp_points)\n",
    "        \n",
    "        #modify it to list of lists\n",
    "        new_data_for_hour = [list(elem) for elem in zipped]\n",
    "       \n",
    "        temp_df= pd.DataFrame(new_data_for_hour, columns=['TimeStamp','ReqDuration'])   \n",
    "        artificial_df= artificial_df.append(temp_df, ignore_index=True) #this function returns a new object\n",
    "    \n",
    "artificial_df= artificial_df.sort_values(by = 'TimeStamp')\n",
    "artificial_df.index = range(696192) #change row indices: to ascending order\n",
    "\n",
    "#### till here, we have a clean generic synthetic data ####\n",
    "\n",
    "#artificial_df.plot(x='TimeStamp',y='ReqDuration')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create feature coulmns and add it to artificial_df ##\n",
    "feature_uniform = np.random.randint(1,5,696192) #discrete uniform distribution: 4 categories (1-4)\n",
    "feature_binomial1= np.random.binomial(4,0.5,696192) #binomial distribution : 5 categories (0-4)\n",
    "feature_binomial2= np.random.binomial(3, 0.3,696192) #binomial distribution : 4 categories (0-3)\n",
    "feature_poisson= np.random.poisson(1,696192) #poisson distribution : approximately 5 categories (0-4)\n",
    "\n",
    "#add coulmns to the end of the dataframe\n",
    "artificial_df['uniform_feature']=feature_uniform\n",
    "artificial_df['binomial1_feature']=feature_binomial1\n",
    "artificial_df['binomial2_feature']=feature_binomial2\n",
    "artificial_df['poisson_feature']=feature_poisson\n",
    "\n",
    "\n",
    "##rearrange coulmns : ReqDuration supposed to be at the end of the frame\n",
    "cols = list(artificial_df)\n",
    "# move the ReqDuration column to the end of the list using index, pop and insert\n",
    "cols.insert(len(cols), cols.pop(cols.index('ReqDuration')))\n",
    "artificial_df = artificial_df.ix[:, cols] \n",
    "\n",
    "#### after this phase we have a clean synthetic with the columns: time stamp, 4 features, request duration ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add outliers in random places by choosing randomly \"problemtic\" features ##\n",
    "\n",
    "num_of_outliers=20 ##trying to add this number of outliers. apperantly will be less outliers:\n",
    "                    ##just if the events in the time stamps will contain the tuples\n",
    "feature_names= ['uniform_feature','binomial1_feature','binomial2_feature','poisson_feature']\n",
    "recorded_outliers=[] ## will contain the \"causes\" for the outliers\n",
    "timestamps_with_outlier=[]\n",
    "\n",
    "for outlier in range (num_of_outliers):\n",
    "    #parameters\n",
    "    start_index_of_outlier= np.random.randint(0,696192,1)[0] #random start point of outlier\n",
    "    duration_of_outlier= np.random.randint(150,650,1)[0] #duration of anomaly, runs over num of indices\n",
    "                                                            #approximately 2-10 minutes\n",
    "    strength_of_outlier = np.random.randint(15,30,1)[0] # for differnt kind of outliers\n",
    "                                                        #our distance in std from the other values\n",
    "    num_of_featurs_in_anomaly= np.random.randint(1,4,1)[0] #allow 1-3 features optionally in anomaly\n",
    "    rand_features = random.sample(feature_names,num_of_featurs_in_anomaly) #list of random features\n",
    "    \n",
    "    #generate (uniformly) random values for each feature. e.g if country was chosen- choose which country\n",
    "    rand_values_of_features= []\n",
    "    for k in range (len(rand_features)):\n",
    "        if (rand_features[k]=='uniform_feature'):\n",
    "            rand_values_of_features.append(np.random.randint(1,5,1)[0])  \n",
    "        elif (rand_features[k]=='binomial1_feature'):\n",
    "            rand_values_of_features.append(np.random.randint(0,5,1)[0])\n",
    "        elif (rand_features[k]=='binomial2_feature'):\n",
    "            rand_values_of_features.append(np.random.randint(0,4,1)[0])            \n",
    "        elif (rand_features[k]== 'poisson_feature'):\n",
    "            rand_values_of_features.append(np.random.randint(0,5,1)[0]) \n",
    "    \n",
    "    \n",
    "    #insert the outlier: run over the events, if tuple was found- update request duration\n",
    "    how_many_events_were_affected=0\n",
    "    cnt=start_index_of_outlier\n",
    "    while (cnt<start_index_of_outlier + duration_of_outlier):\n",
    "        event_contains_feature=True\n",
    "      \n",
    "        #check if event contains the chosen tuple\n",
    "        for j in range(num_of_featurs_in_anomaly):\n",
    "            if(artificial_df.loc[cnt,rand_features[j]]!= rand_values_of_features[j]):\n",
    "                event_contains_feature=False\n",
    "                break\n",
    "        \n",
    "        #update new request duration for this event\n",
    "        if(event_contains_feature):\n",
    "            timestamps_with_outlier.append(artificial_df.loc[cnt,'TimeStamp'])\n",
    "            new_req_duration= artificial_df.loc[cnt,'ReqDuration']+ std*strength_of_outlier\n",
    "            artificial_df.set_value(cnt, 'ReqDuration', new_req_duration)\n",
    "            how_many_events_were_affected+=1 \n",
    "            \n",
    "        cnt+=1\n",
    "    \n",
    "    #if the outlier has an impact: update recorded_outliers\n",
    "    if (how_many_events_were_affected != 0):\n",
    "        start_time=artificial_df.loc[start_index_of_outlier,'TimeStamp']\n",
    "        end_time=artificial_df.loc[start_index_of_outlier + duration_of_outlier ,'TimeStamp']\n",
    "        feature_values=[None for i in range(4)]\n",
    "        \n",
    "        for index,feature in enumerate(rand_features):\n",
    "            if (feature =='uniform_feature'):\n",
    "                feature_values[0]=rand_values_of_features[index]\n",
    "            elif (feature == 'binomial1_feature'):\n",
    "                feature_values[1]=rand_values_of_features[index]\n",
    "            elif (feature == 'binomial2_feature'):\n",
    "                 feature_values[2]=rand_values_of_features[index]\n",
    "            elif (feature == 'poisson_feature'):\n",
    "                feature_values[3]=rand_values_of_features[index]\n",
    "                \n",
    "        temp_list=[start_time,end_time,strength_of_outlier]\n",
    "        \n",
    "        for val in feature_values:\n",
    "            temp_list.append(val)\n",
    "        \n",
    "        #each temp_list is anomaly. add it to the list of anomalies\n",
    "        recorded_outliers.append(temp_list)\n",
    "\n",
    "        \n",
    "#update the artificial anomlies added by us\n",
    "headers=['start time','end time','strength','uniform feature','binomial1 feature','binomial2 feature', 'poisson feature']        \n",
    "df_recorded_outliers = DataFrame(recorded_outliers, columns=headers)\n",
    "df_recorded_outliers = df_recorded_outliers.sort_values(by = 'start time') #sort timestamps\n",
    "df_recorded_outliers.index = range(len(recorded_outliers)) #change row indices: to ascending order\n",
    "\n",
    "\n",
    "#### after this phase we have a synthetic data with artficial outliers made by us ####\n",
    "#### the outliers are recorded ####\n",
    "\n",
    "\n",
    "artificial_df = artificial_df[artificial_df['ReqDuration'] > 0]\n",
    "\n",
    "# aggregated data frame: by 5min\n",
    "artificial_df['TimeStampTrunc'] = artificial_df['TimeStamp'].values.astype('<M8[5m]')\n",
    "agg_artificial_df = artificial_df.groupby(['TimeStampTrunc']).mean()\n",
    "\n",
    "# create data frame of all timestamps of anomlies\n",
    "h=['time stamps']\n",
    "df_timestamps_with_outlier=DataFrame(timestamps_with_outlier,columns=h)\n",
    "df_timestamps_with_outlier = df_timestamps_with_outlier.sort_values(by = 'time stamps')\n",
    "df_timestamps_with_outlier.index = range(len(timestamps_with_outlier))\n",
    "\n",
    "\n",
    "#artificial_df.plot(x='TimeStamp',y='ReqDuration')\n",
    "#plt.show()\n",
    "#agg_artificial_df.plot(y='ReqDuration')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#df_recorded_outliers.to_csv('anomalies.csv')\n",
    "#artificial_df.to_csv('synthetic_data.csv')\n",
    "#df_timestamps_with_outlier.to_csv('anomlies_timestamps.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
